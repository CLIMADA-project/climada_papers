{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add modelled impact to the gridded KGV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find bayes_opt. Module Calib_opt will not work.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xarray as xr\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from scipy import sparse\n",
    "import cartopy.crs as ccrs\n",
    "from climada.engine import Impact, ImpactCalc\n",
    "from climada import CONFIG\n",
    "sys.path.append(str(CONFIG.local_data.func_dir))\n",
    "import scClim as sc\n",
    "\n",
    "data_dir = str(CONFIG.local_data.data_dir)\n",
    "out_dir = str(CONFIG.local_data.out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate impacts\n",
    "years = np.arange(2002,2021+1)\n",
    "haz_var = 'MESHS'\n",
    "event_def_version = 7\n",
    "#load hazard data\n",
    "paths = sc.E.get_hazard_files_TS(haz_var,years,event_def_version,data_dir)\n",
    "haz = sc.hazard_from_radar(paths, extent=[5.8, 10.6, 45.7, 47.9], varname=haz_var) \n",
    "\n",
    "#Expsoure\n",
    "exp = sc.read_xr_exposure(data_dir+'/KGV/ds_building_dmg_v7_1000m.nc','value_exposure')\n",
    "exp_PAA = sc.read_xr_exposure(data_dir+'/KGV/ds_building_dmg_v7_1000m.nc','n_count_exposure')\n",
    "\n",
    "#impact function\n",
    "imp_fun_set = sc.impf_from_csv(data_dir + '/out_files/paa_mdd_smooth_%s%s_v%d.csv'%\n",
    "                               ('KGV',haz_var,event_def_version),smooth=False,\n",
    "                               emanuel_fit=True,plot=False)\n",
    "imp_fun_set_PAA = sc.impf_from_csv(data_dir + '/out_files/paa_mdd_smooth_%s%s_v%d.csv'%('KGV',haz_var,event_def_version),\n",
    "                                PAA_only=True,smooth=False,emanuel_fit=True,plot=False)\n",
    "\n",
    "###############################################################################\n",
    "#Impacts based on crowd-sourced data\n",
    "paths_crowd = xr.open_dataset(data_dir+'/crowd-source/Reports_min100_2017-22.nc')\n",
    "haz_crowd = sc.hazard_from_radar(paths_crowd, extent=[5.8, 10.6, 45.7, 47.9], varname='crowd') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observed impact\n",
    "imp_measured = sc.read_xr_impact(data_dir+'/KGV/ds_building_dmg_v7_1000m.nc','value')\n",
    "imp_measuredPAA = sc.read_xr_impact(data_dir+'/KGV/ds_building_dmg_v7_1000m.nc','n_count',unit='')\n",
    "exp_str = 'KGV'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate impacts\n",
    "imp = ImpactCalc(exp, imp_fun_set, haz).impact(save_mat=True)\n",
    "imp_PAA = ImpactCalc(exp_PAA, imp_fun_set_PAA, haz).impact(save_mat=True)\n",
    "\n",
    "#scale impact to account for changing exposure\n",
    "scale_factor_year = pd.read_csv(data_dir+'/out_files/constants/KGV_scale_factor.csv',index_col=0)\n",
    "year=np.array([dt.datetime.fromordinal(d).year for d in imp.date])\n",
    "scale_arr = scale_factor_year.loc[year,'scale_factor'].values\n",
    "scale_arrPAA = scale_factor_year.loc[year,'scale_factorPAA'].values\n",
    "\n",
    "#elementwise multiplication (1d scale_factor * 2d impact matrix)\n",
    "atEvent = scale_arr*imp.at_event\n",
    "impMat = sparse.csr_matrix(np.multiply(scale_arr[:,None],imp.imp_mat.todense()))\n",
    "atEventPAA = scale_arrPAA*imp_PAA.at_event\n",
    "impMatPAA = sparse.csr_matrix(np.multiply(scale_arrPAA[:,None],imp_PAA.imp_mat.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ds_KGV\n",
    "ds_KGV = xr.open_dataset(data_dir+'/KGV/ds_building_dmg_v7_1000m.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "#extend ds_KGV with additional dates\n",
    "imp_dates = [dt.datetime.fromordinal(int(d)) for d in imp.date[imp.at_event>0]]\n",
    "impPAA_dates = [dt.datetime.fromordinal(int(d)) for d in imp_PAA.date[imp_PAA.at_event>0]]\n",
    "#assert that all dates with either imp>0 or imp_PAA>0 are added\n",
    "assert(all([d in impPAA_dates for d in imp_dates]))\n",
    "\n",
    "#select dates that are not yet in ds_KGV\n",
    "add_dates = np.array([dt.datetime.fromordinal(int(d)) for d in imp.date[imp_PAA.at_event>0] \n",
    "                      if dt.datetime.fromordinal(int(d)).strftime('%Y-%m-%d') not in \n",
    "                      ds_KGV.date.dt.strftime('%Y-%m-%d')])\n",
    "print(len(add_dates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new values to ds_KGV.date \n",
    "ds_KGV_add = ds_KGV[['value','Versicherungssumme','n_count','PAA','MDR']].copy(deep=True)\n",
    "\n",
    "#make add_KGV the same length as add_dates and set date to add_dates\n",
    "ds_KGV_add = ds_KGV_add.isel(date=slice(0,len(add_dates))) #=add_dates\n",
    "ds_KGV_add['date'] = xr.DataArray(add_dates,dims='date')\n",
    "\n",
    "#set all values to nan for dates where no impact is observed (but some impact is modelled)\n",
    "for data_var in ['value','Versicherungssumme','n_count','PAA','MDR']:\n",
    "    ds_KGV_add[data_var] = np.nan \n",
    "\n",
    "#merge with ds_KGV\n",
    "ds_KGV = xr.merge([ds_KGV,ds_KGV_add])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add modelled damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = np.reshape(imp.coord_exp[:,0],(len(ds_KGV.chy),len(ds_KGV.chx)))\n",
    "latOrig = ds_KGV.lat.values\n",
    "np.testing.assert_array_almost_equal(lat,latOrig)\n",
    "lon = np.reshape(imp.coord_exp[:,1],(len(ds_KGV.chy),len(ds_KGV.chx)))\n",
    "lonOrig = ds_KGV.lon.values\n",
    "np.testing.assert_array_almost_equal(lon,lonOrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_dates = np.array([dt.datetime.fromordinal(int(d)).strftime('%Y-%m-%d') in \n",
    "                      ds_KGV.date.dt.strftime('%Y-%m-%d') for d in imp.date]) \n",
    "                      #Note that sel_dates actually corresponds to all dates now\n",
    "print(sum(sel_dates))\n",
    "imp_sel = imp.select(event_ids=imp.event_id[sel_dates])\n",
    "impResh= np.reshape(imp_sel.imp_mat.toarray(),(imp_sel.imp_mat.shape[0],len(ds_KGV.chy),len(ds_KGV.chx)))\n",
    "ds_KGV['imp_MESHS'] = (('date','chy','chx'),impResh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add modelled PAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(imp.date,imp_PAA.date)\n",
    "np.testing.assert_array_equal(imp.coord_exp,imp_PAA.coord_exp)\n",
    "impPAA_sel = imp_PAA.select(event_ids=imp_PAA.event_id[sel_dates])\n",
    "impPAAResh= np.reshape(impPAA_sel.imp_mat.toarray(),(impPAA_sel.imp_mat.shape[0],len(ds_KGV.chy),len(ds_KGV.chx)))\n",
    "ds_KGV['n_buildings_MESHS'] = (('date','chy','chx'),impPAAResh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add crowd_sourced modelled damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impC = Impact.from_csv(data_dir+'/KGV/imp_modelled_crowd.csv')\n",
    "impC.imp_mat = Impact.read_sparse_csr(data_dir+'/KGV/imp_modelled_crowd.npz')\n",
    "sel_dates = np.array([dt.datetime.fromordinal(int(d)).strftime('%Y-%m-%d') in \n",
    "                      ds_KGV.date.dt.strftime('%Y-%m-%d') for d in impC.date])\n",
    "impC_sel = impC.select(event_ids=impC.event_id[sel_dates])\n",
    "impC_dates = np.array([dt.datetime.fromordinal(int(d)) for d in impC_sel.date])\n",
    "impReshC= np.reshape(impC_sel.imp_mat.toarray(),\n",
    "                     (impC_sel.imp_mat.shape[0],len(ds_KGV.chy),len(ds_KGV.chx)))\n",
    "crowd_xr = xr.Dataset({'imp_crowd': (('date','chy','chx'),impReshC)},\n",
    "                      coords={'date':impC_dates,'chy':ds_KGV.chy,'chx':ds_KGV.chx})\n",
    "ds_KGV['imp_crowd'] =crowd_xr.imp_crowd\n",
    "\n",
    "#PAA\n",
    "impC_PAA = Impact.from_csv(data_dir+'/KGV/imp_modelledPAA_crowd.csv')\n",
    "impC_PAA.imp_mat = Impact.read_sparse_csr(data_dir+'/KGV/imp_modelledPAA_crowd.npz')\n",
    "np.testing.assert_array_equal(impC.date,impC_PAA.date)\n",
    "np.testing.assert_array_equal(impC.coord_exp,impC_PAA.coord_exp)\n",
    "impC_PAA_sel = impC_PAA.select(event_ids=impC_PAA.event_id[sel_dates])\n",
    "# impPAACmat_sorted = impPAA_sel.imp_mat[impPAA_sel.date.argsort(),:]\n",
    "impC_PAAResh= np.reshape(impC_PAA_sel.imp_mat.toarray(),\n",
    "                         (impC_PAA_sel.imp_mat.shape[0],len(ds_KGV.chy),len(ds_KGV.chx)))\n",
    "\n",
    "crowdPAA_xr = xr.Dataset({'imp_crowdPAA': (('date','chy','chx'),impC_PAAResh)},\n",
    "                         coords={'date':impC_dates,'chy':ds_KGV.chy,'chx':ds_KGV.chx})\n",
    "ds_KGV['n_buildings_crowd'] =crowdPAA_xr.imp_crowdPAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add modelled_PAA\n",
    "ds_KGV['PAA_MESHS'] = ds_KGV.n_buildings_MESHS/ds_KGV.n_count_exposure\n",
    "ds_KGV['PAA_crowd'] = ds_KGV.n_buildings_crowd/ds_KGV.n_count_exposure\n",
    "\n",
    "#save as netcdf\n",
    "ds_KGV.to_netcdf(data_dir+'/KGV/ds_building_dmg_v7_1000m_wModImp.nc',encoding={\n",
    "    \"value\":            {'zlib':True,'complevel':5},\n",
    "    \"Versicherungssumme\":{'zlib':True,'complevel':5},\n",
    "    \"n_count\":          {'zlib':True,'complevel':5},\n",
    "    \"PAA\":              {'zlib':True,'complevel':5},\n",
    "    \"MDR\":              {'zlib':True,'complevel':5},\n",
    "    \"Baujahr_exposure\": {'zlib':True,'complevel':5},\n",
    "    \"value_exposure\":   {'zlib':True,'complevel':5},\n",
    "    \"n_count_exposure\": {'zlib':True,'complevel':5},\n",
    "    \"imp_MESHS\":        {'zlib':True,'complevel':5},\n",
    "    \"n_buildings_MESHS\":{'zlib':True,'complevel':5},\n",
    "    \"imp_crowd\":        {'zlib':True,'complevel':5},\n",
    "    \"n_buildings_crowd\":{'zlib':True,'complevel':5},\n",
    "    \"PAA_MESHS\":        {'zlib':True,'complevel':5},\n",
    "    \"PAA_crowd\":        {'zlib':True,'complevel':5},\n",
    "    #\"MESHS\":            {'zlib':True,'complevel':5}, #takes over 12min to compress\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climada_env_optimize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b9964aef281d6ecd7a1426a3be32c90501b2e2a8f294fb003c18a74caeb307f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
